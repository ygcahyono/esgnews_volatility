{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5df8cf6e",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b94abc6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T18:37:02.968618Z",
     "start_time": "2023-08-12T18:36:58.644706Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping\n",
    "sys.path.append('../python')\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from dataprocessingnew2 import *\n",
    "from runmodels import *\n",
    "from LSTM_MS import *\n",
    "# from util import Run_Algorithms\n",
    "\n",
    "import glob\n",
    "\n",
    "# dataprocessing = DataProcessing('2006-01-01', '2022-12-01', daily=True)\n",
    "# df_clean, train_df, test_df = dataprocessing.clean_final(fillna = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cdb56e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T18:36:57.883264Z",
     "start_time": "2023-08-12T18:36:57.054692Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %store train_df\n",
    "# %store test_df\n",
    "\n",
    "%store -r train_df\n",
    "%store -r test_df\n",
    "\n",
    "len(train_df.Asset.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0de4891d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T18:37:20.588110Z",
     "start_time": "2023-08-12T18:37:20.263037Z"
    }
   },
   "outputs": [],
   "source": [
    "coverage_df = pd.read_csv('../data/coverage_dataframe.csv')[['PermID', 'Name', 'TRBCEconomicSector']]\n",
    "coverage_df['PermID'] = coverage_df.PermID.astype(int)\n",
    "\n",
    "unique_assets_df = pd.DataFrame({\n",
    "    'Assets': train_df.Asset.unique()\n",
    "})\n",
    "\n",
    "unique_assets_df = pd.merge(unique_assets_df, coverage_df, how = 'left', left_on = 'Assets', right_on= 'PermID')\n",
    "unique_assets_df = unique_assets_df.iloc[:, 1:]\n",
    "unique_assets_df.columns = ['Assets', 'Firm Name', 'Economic Sector']\n",
    "\n",
    "sectors_df = pd.DataFrame(np.unique(unique_assets_df['Economic Sector'], return_counts=True)).T\n",
    "sectors_df.columns = ['sectors','num_firms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b05bb9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T18:38:10.059720Z",
     "start_time": "2023-08-12T18:38:10.051679Z"
    }
   },
   "outputs": [],
   "source": [
    "# cols = ['vol_series_daily', 'vol_series_weekly', 'vol_series_monthly',\n",
    "#         'buzz','ESG','ESGCombined','ESGControversies', 'EnvironmentalPillar',\n",
    "#         'GovernancePillar','SocialPillar','Community','EnvironmentalInnovation',\n",
    "#         'Management','ProductResponsibility','Shareholders','Workforce', 'V^YZ']\n",
    "\n",
    "# cols = ['vol_series_daily', 'vol_series_weekly', 'vol_series_monthly',\n",
    "#         'buzz', 'EnvironmentalPillar', 'Community','Shareholders', 'V^YZ']\n",
    "\n",
    "# cols = ['vol_series_daily', 'vol_series_weekly', 'vol_series_monthly', 'V^YZ']\n",
    "\n",
    "cols = ['vol_series_daily', 'vol_series_weekly', 'vol_series_monthly', 'buzz', 'ESG', 'ESGCombined', 'ESGControversies', 'EnvironmentalPillar', 'GovernancePillar', 'SocialPillar', 'Community', 'EnvironmentalInnovation', 'Management', 'ProductResponsibility', 'Shareholders', 'Workforce', 'noise_beta_0.0_gamma_0.25', 'V^YZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2ea776e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T18:38:11.190692Z",
     "start_time": "2023-08-12T18:38:11.186497Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd43eadd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T18:38:12.262388Z",
     "start_time": "2023-08-12T18:38:12.247876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assets</th>\n",
       "      <th>Firm Name</th>\n",
       "      <th>Economic Sector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4295874865</td>\n",
       "      <td>DCC PLC</td>\n",
       "      <td>Consumer non-cyclicals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4295893899</td>\n",
       "      <td>Berkeley Group Holdings PLC</td>\n",
       "      <td>Consumer cyclicals</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Assets                    Firm Name         Economic Sector\n",
       "0  4295874865                      DCC PLC  Consumer non-cyclicals\n",
       "1  4295893899  Berkeley Group Holdings PLC      Consumer cyclicals"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_assets_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fe64040",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T18:38:13.097678Z",
     "start_time": "2023-08-12T18:38:13.093214Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bf90bcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T18:38:13.956535Z",
     "start_time": "2023-08-12T18:38:13.943733Z"
    }
   },
   "outputs": [],
   "source": [
    "def vis_line_plot_results(y_pred, y_test, name, r):\n",
    "\n",
    "    dictionaries = {\n",
    "        'EN': 'Elastic Net',\n",
    "        'RF': 'Random Forest',\n",
    "        'LSTM': 'Long Short-Term Memory',\n",
    "        'HAR': 'Heterogeneous AutoRegressive',\n",
    "        'GARCH': 'Generalised AutoRegressive Conditional Heteroskedasticity'\n",
    "    }\n",
    "\n",
    "    algorithms = 'EN'\n",
    "    features = 'm3'\n",
    "\n",
    "    # Calculate absolute differences between actual and predicted values\n",
    "    diff = np.abs(y_test - y_pred)\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(10,5))\n",
    "\n",
    "    # Plot actual and predicted values\n",
    "    ax1.plot(y_test, alpha = 0.7, color = 'black')\n",
    "    ax1.plot(y_pred, marker='.')\n",
    "    ax1.legend(['True Volatility', 'Predicted Volatility'], fontsize=7.5, loc='upper left')\n",
    "    ax1.grid(axis='y', alpha=0.5)\n",
    "    ax1.set_ylabel('Volatility', fontsize=9)\n",
    "    # print(np.min(y_test))\n",
    "    ax1.set_ylim([np.min(y_test)-np.min(y_test)*.5, np.max(y_test)+np.max(y_test)*.05]) \n",
    "\n",
    "    # Create a second y-axis\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    # Plot differences on the secondary y-axis as a bar chart\n",
    "    ax2.bar(y_test.index, diff, color='gray', alpha=0.8, width=1.5)\n",
    "    ax2.legend(['Absolute Difference'], fontsize=7.5, loc='upper right')\n",
    "    ax2.set_ylabel('Absolute Difference', fontsize=9)\n",
    "\n",
    "    # Setting y-limits for the second axis to prevent overlap with line plots\n",
    "    ax2.set_ylim([0, np.max(diff)*3]) \n",
    "\n",
    "    # Set main title\n",
    "    plt.title(f'{dictionaries[algorithms]} Prediction on \"{name}\" [Data:{features}]', fontsize=12)\n",
    "\n",
    "    plt.xticks(rotation=0)\n",
    "\n",
    "    plt.savefig(f'../outputs/{algorithms}-{features}/{str(r+1).zfill(3)}-{algorithms}-{name}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc9697c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T18:38:16.354684Z",
     "start_time": "2023-08-12T18:38:16.348382Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vol_series_daily',\n",
       " 'vol_series_weekly',\n",
       " 'vol_series_monthly',\n",
       " 'buzz',\n",
       " 'ESG',\n",
       " 'ESGCombined',\n",
       " 'ESGControversies',\n",
       " 'EnvironmentalPillar',\n",
       " 'GovernancePillar',\n",
       " 'SocialPillar',\n",
       " 'Community',\n",
       " 'EnvironmentalInnovation',\n",
       " 'Management',\n",
       " 'ProductResponsibility',\n",
       " 'Shareholders',\n",
       " 'Workforce',\n",
       " 'noise_beta_0.0_gamma_0.25',\n",
       " 'V^YZ']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "969b06d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T19:18:14.700003Z",
     "start_time": "2023-08-12T18:38:22.867894Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n"
     ]
    }
   ],
   "source": [
    "train_dfs, test_dfs = [], []\n",
    "target = 'V^YZ'\n",
    "# X_train, y_train = np.asarray([]), np.asarray([])\n",
    "\n",
    "# Define the hyperparameters\n",
    "param_grid = {\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "    'l1_ratio': [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "}\n",
    "\n",
    "master_df = pd.DataFrame()\n",
    "\n",
    "for row, i in enumerate(unique_assets_df.Assets):\n",
    "    \n",
    "    asset_data = train_df[train_df.Asset == i]\n",
    "    train_indexes = asset_data.index\n",
    "    asset_data = asset_data.reset_index(drop=True)\n",
    "    \n",
    "    asset_test_data = test_df[test_df.Asset == i][cols]\n",
    "    test_indexes = asset_test_data.index\n",
    "    asset_test_data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    ids = unique_assets_df.iloc[row, 0]\n",
    "    name = unique_assets_df.iloc[row, 1]\n",
    "    \n",
    "    train_size = int(0.8 * len(asset_data))\n",
    "    sub_train_df = asset_data.iloc[:train_size][cols]\n",
    "    sub_test_df = asset_data.iloc[train_size:][cols]\n",
    "    \n",
    "    \n",
    "    X_sub_train_df = sub_train_df.drop([target], axis=1)\n",
    "    Y_sub_train_df = sub_train_df[target].reset_index(drop=True)\n",
    "    \n",
    "    X_sub_test_df = sub_test_df.drop([target], axis=1)\n",
    "    Y_sub_test_df = sub_test_df[target].reset_index(drop=True)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_sub_train_df = pd.DataFrame(scaler.fit_transform(X_sub_train_df))\n",
    "    X_sub_test_df = pd.DataFrame(scaler.transform(X_sub_test_df))\n",
    "\n",
    "    \n",
    "    sub_train_df = pd.concat([X_sub_train_df, Y_sub_train_df], axis=1)\n",
    "    sub_test_df = pd.concat([X_sub_test_df, Y_sub_test_df], axis=1)\n",
    "\n",
    "    sub_train_df.columns = cols\n",
    "    sub_test_df.columns = cols\n",
    "\n",
    "    merge_df = pd.concat([sub_train_df, sub_test_df])\n",
    "    \n",
    "    X_train = merge_df[cols].drop([target], axis=1)\n",
    "    y_train = merge_df[target]\n",
    "    \n",
    "    # Initialize ElasticNet\n",
    "    model = ElasticNet(max_iter=10000) # Increased max_iter for convergence\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    # Initialize Grid Search\n",
    "    gsearch = GridSearchCV(estimator=model, cv=tscv,\n",
    "                           param_grid=param_grid, \n",
    "                           verbose=1, \n",
    "                           scoring='neg_mean_squared_error')\n",
    "\n",
    "    # display(X_train)\n",
    "    # Fit the grid search\n",
    "    gsearch.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    X_test = asset_test_data.drop([target], axis=1)\n",
    "    y_test = asset_test_data[target]\n",
    "    \n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    model = ElasticNet(max_iter=10000, alpha= gsearch.best_params_['alpha']\n",
    "                       , l1_ratio = gsearch.best_params_['l1_ratio']) \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_hat = model.predict(X_test)\n",
    "\n",
    "    mse_test = mean_squared_error(y_hat, y_test)\n",
    "    \n",
    "    y_hat = pd.Series(y_hat, index=test_indexes)\n",
    "    y_test = pd.Series(y_test.values, index=test_indexes)\n",
    "    \n",
    "    vis_line_plot_results(y_hat, y_test, name, row)\n",
    "    \n",
    "    # display(X_train)\n",
    "    temp_df = pd.DataFrame({\n",
    "        'L1 Ratio': gsearch.best_params_['l1_ratio'],\n",
    "        'Alpha': gsearch.best_params_['alpha'],\n",
    "        'Best Scores': gsearch.best_score_*-1 *10**3,\n",
    "        'MSE': mse_test*10**3,\n",
    "        'Asset IDs': ids\n",
    "    },\n",
    "    index = [row+1])\n",
    "    # display(temp_df)\n",
    "    \n",
    "    master_df = pd.concat([master_df, temp_df])\n",
    "    \n",
    "    # dftrain = pd.concat(train_dfs, ignore_index=True)\n",
    "    # dftest = pd.concat(test_dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "    # train_dfs = scaler.fit_transform(train_dfs)\n",
    "    # test_dfs = scaler.transform(test_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebd45518",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T19:18:14.835499Z",
     "start_time": "2023-08-12T19:18:14.712003Z"
    }
   },
   "outputs": [],
   "source": [
    "master_df.to_csv('../results/EN-M4-GRIDSEARCH.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b92347f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T19:18:14.848437Z",
     "start_time": "2023-08-12T19:18:14.846085Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['vol_series_daily', 'vol_series_weekly', 'vol_series_monthly', 'buzz', 'ESG', 'ESGCombined', 'ESGControversies', 'EnvironmentalPillar', 'GovernancePillar', 'SocialPillar', 'Community', 'EnvironmentalInnovation', 'Management', 'ProductResponsibility', 'Shareholders', 'Workforce', 'noise_beta_0.0_gamma_0.25', 'noise_beta_0.0_gamma_0.5', 'noise_beta_0.0_gamma_1.0', 'noise_beta_0.5_gamma_0.25', 'noise_beta_0.5_gamma_0.5', 'V^YZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4a7effa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T20:07:40.276702Z",
     "start_time": "2023-08-12T19:18:14.850473Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n"
     ]
    }
   ],
   "source": [
    "train_dfs, test_dfs = [], []\n",
    "target = 'V^YZ'\n",
    "# X_train, y_train = np.asarray([]), np.asarray([])\n",
    "\n",
    "# Define the hyperparameters\n",
    "param_grid = {\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "    'l1_ratio': [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "}\n",
    "\n",
    "master_df = pd.DataFrame()\n",
    "\n",
    "for row, i in enumerate(unique_assets_df.Assets):\n",
    "    \n",
    "    asset_data = train_df[train_df.Asset == i]\n",
    "    train_indexes = asset_data.index\n",
    "    asset_data = asset_data.reset_index(drop=True)\n",
    "    \n",
    "    asset_test_data = test_df[test_df.Asset == i][cols]\n",
    "    test_indexes = asset_test_data.index\n",
    "    asset_test_data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    ids = unique_assets_df.iloc[row, 0]\n",
    "    name = unique_assets_df.iloc[row, 1]\n",
    "    \n",
    "    train_size = int(0.8 * len(asset_data))\n",
    "    sub_train_df = asset_data.iloc[:train_size][cols]\n",
    "    sub_test_df = asset_data.iloc[train_size:][cols]\n",
    "    \n",
    "    \n",
    "    X_sub_train_df = sub_train_df.drop([target], axis=1)\n",
    "    Y_sub_train_df = sub_train_df[target].reset_index(drop=True)\n",
    "    \n",
    "    X_sub_test_df = sub_test_df.drop([target], axis=1)\n",
    "    Y_sub_test_df = sub_test_df[target].reset_index(drop=True)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_sub_train_df = pd.DataFrame(scaler.fit_transform(X_sub_train_df))\n",
    "    X_sub_test_df = pd.DataFrame(scaler.transform(X_sub_test_df))\n",
    "\n",
    "    \n",
    "    sub_train_df = pd.concat([X_sub_train_df, Y_sub_train_df], axis=1)\n",
    "    sub_test_df = pd.concat([X_sub_test_df, Y_sub_test_df], axis=1)\n",
    "\n",
    "    sub_train_df.columns = cols\n",
    "    sub_test_df.columns = cols\n",
    "\n",
    "    merge_df = pd.concat([sub_train_df, sub_test_df])\n",
    "    \n",
    "    X_train = merge_df[cols].drop([target], axis=1)\n",
    "    y_train = merge_df[target]\n",
    "    \n",
    "    # Initialize ElasticNet\n",
    "    model = ElasticNet(max_iter=10000) # Increased max_iter for convergence\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    # Initialize Grid Search\n",
    "    gsearch = GridSearchCV(estimator=model, cv=tscv,\n",
    "                           param_grid=param_grid, \n",
    "                           verbose=1, \n",
    "                           scoring='neg_mean_squared_error')\n",
    "\n",
    "    # display(X_train)\n",
    "    # Fit the grid search\n",
    "    gsearch.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    X_test = asset_test_data.drop([target], axis=1)\n",
    "    y_test = asset_test_data[target]\n",
    "    \n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    model = ElasticNet(max_iter=10000, alpha= gsearch.best_params_['alpha']\n",
    "                       , l1_ratio = gsearch.best_params_['l1_ratio']) \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_hat = model.predict(X_test)\n",
    "\n",
    "    mse_test = mean_squared_error(y_hat, y_test)\n",
    "    \n",
    "    y_hat = pd.Series(y_hat, index=test_indexes)\n",
    "    y_test = pd.Series(y_test.values, index=test_indexes)\n",
    "    \n",
    "    vis_line_plot_results(y_hat, y_test, name, row)\n",
    "    \n",
    "    # display(X_train)\n",
    "    temp_df = pd.DataFrame({\n",
    "        'L1 Ratio': gsearch.best_params_['l1_ratio'],\n",
    "        'Alpha': gsearch.best_params_['alpha'],\n",
    "        'Best Scores': gsearch.best_score_*-1 *10**3,\n",
    "        'MSE': mse_test*10**3,\n",
    "        'Asset IDs': ids\n",
    "    },\n",
    "    index = [row+1])\n",
    "    # display(temp_df)\n",
    "    \n",
    "    master_df = pd.concat([master_df, temp_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f366ad5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T20:07:40.292336Z",
     "start_time": "2023-08-12T20:07:40.281514Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['vol_series_daily', 'vol_series_weekly', 'vol_series_monthly', 'buzz', 'ESG', 'ESGCombined', 'ESGControversies', 'EnvironmentalPillar', 'GovernancePillar', 'SocialPillar', 'Community', 'EnvironmentalInnovation', 'Management', 'ProductResponsibility', 'Shareholders', 'Workforce', 'noise_beta_0.0_gamma_0.25', 'noise_beta_0.0_gamma_0.5', 'noise_beta_0.0_gamma_1.0', 'noise_beta_0.5_gamma_0.25', 'noise_beta_0.5_gamma_0.5', 'noise_beta_0.5_gamma_1.0', 'noise_beta_0.75_gamma_0.25', 'noise_beta_0.75_gamma_0.5', 'noise_beta_0.75_gamma_1.0', 'noise_beta_0.9_gamma_0.25', 'V^YZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55dd70c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T20:07:40.308580Z",
     "start_time": "2023-08-12T20:07:40.293345Z"
    }
   },
   "outputs": [],
   "source": [
    "master_df.to_csv('../results/EN-M5-GRIDSEARCH.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7295efcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T21:08:55.624780Z",
     "start_time": "2023-08-12T20:07:40.309951Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n"
     ]
    }
   ],
   "source": [
    "train_dfs, test_dfs = [], []\n",
    "target = 'V^YZ'\n",
    "# X_train, y_train = np.asarray([]), np.asarray([])\n",
    "\n",
    "# Define the hyperparameters\n",
    "param_grid = {\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "    'l1_ratio': [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "}\n",
    "\n",
    "master_df = pd.DataFrame()\n",
    "\n",
    "for row, i in enumerate(unique_assets_df.Assets):\n",
    "    \n",
    "    asset_data = train_df[train_df.Asset == i]\n",
    "    train_indexes = asset_data.index\n",
    "    asset_data = asset_data.reset_index(drop=True)\n",
    "    \n",
    "    asset_test_data = test_df[test_df.Asset == i][cols]\n",
    "    test_indexes = asset_test_data.index\n",
    "    asset_test_data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    ids = unique_assets_df.iloc[row, 0]\n",
    "    name = unique_assets_df.iloc[row, 1]\n",
    "    \n",
    "    train_size = int(0.8 * len(asset_data))\n",
    "    sub_train_df = asset_data.iloc[:train_size][cols]\n",
    "    sub_test_df = asset_data.iloc[train_size:][cols]\n",
    "    \n",
    "    \n",
    "    X_sub_train_df = sub_train_df.drop([target], axis=1)\n",
    "    Y_sub_train_df = sub_train_df[target].reset_index(drop=True)\n",
    "    \n",
    "    X_sub_test_df = sub_test_df.drop([target], axis=1)\n",
    "    Y_sub_test_df = sub_test_df[target].reset_index(drop=True)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_sub_train_df = pd.DataFrame(scaler.fit_transform(X_sub_train_df))\n",
    "    X_sub_test_df = pd.DataFrame(scaler.transform(X_sub_test_df))\n",
    "\n",
    "    \n",
    "    sub_train_df = pd.concat([X_sub_train_df, Y_sub_train_df], axis=1)\n",
    "    sub_test_df = pd.concat([X_sub_test_df, Y_sub_test_df], axis=1)\n",
    "\n",
    "    sub_train_df.columns = cols\n",
    "    sub_test_df.columns = cols\n",
    "\n",
    "    merge_df = pd.concat([sub_train_df, sub_test_df])\n",
    "    \n",
    "    X_train = merge_df[cols].drop([target], axis=1)\n",
    "    y_train = merge_df[target]\n",
    "    \n",
    "    # Initialize ElasticNet\n",
    "    model = ElasticNet(max_iter=10000) # Increased max_iter for convergence\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    # Initialize Grid Search\n",
    "    gsearch = GridSearchCV(estimator=model, cv=tscv,\n",
    "                           param_grid=param_grid, \n",
    "                           verbose=1, \n",
    "                           scoring='neg_mean_squared_error')\n",
    "\n",
    "    # display(X_train)\n",
    "    # Fit the grid search\n",
    "    gsearch.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    X_test = asset_test_data.drop([target], axis=1)\n",
    "    y_test = asset_test_data[target]\n",
    "    \n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    model = ElasticNet(max_iter=10000, alpha= gsearch.best_params_['alpha']\n",
    "                       , l1_ratio = gsearch.best_params_['l1_ratio']) \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_hat = model.predict(X_test)\n",
    "\n",
    "    mse_test = mean_squared_error(y_hat, y_test)\n",
    "    \n",
    "    y_hat = pd.Series(y_hat, index=test_indexes)\n",
    "    y_test = pd.Series(y_test.values, index=test_indexes)\n",
    "    \n",
    "    vis_line_plot_results(y_hat, y_test, name, row)\n",
    "    \n",
    "    # display(X_train)\n",
    "    temp_df = pd.DataFrame({\n",
    "        'L1 Ratio': gsearch.best_params_['l1_ratio'],\n",
    "        'Alpha': gsearch.best_params_['alpha'],\n",
    "        'Best Scores': gsearch.best_score_*-1 *10**3,\n",
    "        'MSE': mse_test*10**3,\n",
    "        'Asset IDs': ids\n",
    "    },\n",
    "    index = [row+1])\n",
    "    # display(temp_df)\n",
    "    \n",
    "    master_df = pd.concat([master_df, temp_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba7e512a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T21:08:55.684764Z",
     "start_time": "2023-08-12T21:08:55.639453Z"
    }
   },
   "outputs": [],
   "source": [
    "master_df.to_csv('../results/EN-M6-GRIDSEARCH.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0def7de3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "12b17348",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T21:23:52.931312Z",
     "start_time": "2023-08-07T21:23:52.915879Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1 Ratio</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Best Scores</th>\n",
       "      <th>MSE</th>\n",
       "      <th>Asset IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.077503</td>\n",
       "      <td>0.084326</td>\n",
       "      <td>4295874865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.102921</td>\n",
       "      <td>0.016746</td>\n",
       "      <td>4295893899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   L1 Ratio  Alpha  Best Scores       MSE   Asset IDs\n",
       "1       0.6  0.001     0.077503  0.084326  4295874865\n",
       "2       0.7  0.010     0.102921  0.016746  4295893899"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "bf9c09f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T21:25:04.061944Z",
     "start_time": "2023-08-07T21:25:04.005772Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c0ef14c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T21:40:43.542883Z",
     "start_time": "2023-08-07T21:40:43.516402Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08391125942861427"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(master_df['Best Scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c5d1c30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T21:40:44.105519Z",
     "start_time": "2023-08-07T21:40:44.098550Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08463398947666778"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(master_df['MSE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f814d937",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T21:35:40.752594Z",
     "start_time": "2023-08-07T21:35:40.701573Z"
    }
   },
   "outputs": [],
   "source": [
    "master_df.to_csv('../results/EN-M2-GRIDSEARCH.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4338bed4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T21:43:30.540578Z",
     "start_time": "2023-08-07T21:43:30.453284Z"
    }
   },
   "outputs": [],
   "source": [
    "master_df.to_csv('../results/EN-M1-GRIDSEARCH.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca2700a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9dab67f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T18:19:09.040200Z",
     "start_time": "2023-08-09T18:19:08.936311Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1 Ratio</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Best Scores</th>\n",
       "      <th>MSE</th>\n",
       "      <th>Asset IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>8.500000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.217647</td>\n",
       "      <td>0.197984</td>\n",
       "      <td>0.083911</td>\n",
       "      <td>0.084634</td>\n",
       "      <td>4.693753e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.293248</td>\n",
       "      <td>0.389159</td>\n",
       "      <td>0.064645</td>\n",
       "      <td>0.280734</td>\n",
       "      <td>1.107719e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.015364</td>\n",
       "      <td>0.003928</td>\n",
       "      <td>4.295869e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.039857</td>\n",
       "      <td>0.016133</td>\n",
       "      <td>4.295895e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.056647</td>\n",
       "      <td>0.029773</td>\n",
       "      <td>4.295895e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.103739</td>\n",
       "      <td>0.044203</td>\n",
       "      <td>4.295899e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.307140</td>\n",
       "      <td>2.334567</td>\n",
       "      <td>8.589934e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        L1 Ratio      Alpha  Best Scores        MSE     Asset IDs\n",
       "count  85.000000  85.000000    85.000000  85.000000  8.500000e+01\n",
       "mean    0.217647   0.197984     0.083911   0.084634  4.693753e+09\n",
       "std     0.293248   0.389159     0.064645   0.280734  1.107719e+09\n",
       "min     0.000000   0.000100     0.015364   0.003928  4.295869e+09\n",
       "25%     0.000000   0.001000     0.039857   0.016133  4.295895e+09\n",
       "50%     0.100000   0.010000     0.056647   0.029773  4.295895e+09\n",
       "75%     0.300000   0.010000     0.103739   0.044203  4.295899e+09\n",
       "max     1.000000   1.000000     0.307140   2.334567  8.589934e+09"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d12d4a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T18:19:18.467190Z",
     "start_time": "2023-08-09T18:19:18.443352Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1 Ratio</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Best Scores</th>\n",
       "      <th>MSE</th>\n",
       "      <th>Asset IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>8.500000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.255954</td>\n",
       "      <td>0.087920</td>\n",
       "      <td>0.089043</td>\n",
       "      <td>4.693753e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.271602</td>\n",
       "      <td>0.429089</td>\n",
       "      <td>0.067993</td>\n",
       "      <td>0.283528</td>\n",
       "      <td>1.107719e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.015274</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>4.295869e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.042374</td>\n",
       "      <td>0.016297</td>\n",
       "      <td>4.295895e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.061010</td>\n",
       "      <td>0.029007</td>\n",
       "      <td>4.295895e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.112480</td>\n",
       "      <td>0.044632</td>\n",
       "      <td>4.295899e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.318984</td>\n",
       "      <td>2.334567</td>\n",
       "      <td>8.589934e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        L1 Ratio      Alpha  Best Scores        MSE     Asset IDs\n",
       "count  85.000000  85.000000    85.000000  85.000000  8.500000e+01\n",
       "mean    0.270588   0.255954     0.087920   0.089043  4.693753e+09\n",
       "std     0.271602   0.429089     0.067993   0.283528  1.107719e+09\n",
       "min     0.000000   0.000100     0.015274   0.004325  4.295869e+09\n",
       "25%     0.000000   0.010000     0.042374   0.016297  4.295895e+09\n",
       "50%     0.200000   0.010000     0.061010   0.029007  4.295895e+09\n",
       "75%     0.400000   0.100000     0.112480   0.044632  4.295899e+09\n",
       "max     1.000000   1.000000     0.318984   2.334567  8.589934e+09"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1024d38a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T18:19:24.786766Z",
     "start_time": "2023-08-09T18:19:24.745865Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1 Ratio</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Best Scores</th>\n",
       "      <th>MSE</th>\n",
       "      <th>Asset IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>8.500000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.345882</td>\n",
       "      <td>0.148049</td>\n",
       "      <td>0.089377</td>\n",
       "      <td>0.093803</td>\n",
       "      <td>4.693753e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.275401</td>\n",
       "      <td>0.347485</td>\n",
       "      <td>0.068611</td>\n",
       "      <td>0.293993</td>\n",
       "      <td>1.107719e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.015301</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>4.295869e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.041463</td>\n",
       "      <td>0.016492</td>\n",
       "      <td>4.295895e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.062155</td>\n",
       "      <td>0.028661</td>\n",
       "      <td>4.295895e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.114836</td>\n",
       "      <td>0.047029</td>\n",
       "      <td>4.295899e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.312227</td>\n",
       "      <td>2.334567</td>\n",
       "      <td>8.589934e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        L1 Ratio      Alpha  Best Scores        MSE     Asset IDs\n",
       "count  85.000000  85.000000    85.000000  85.000000  8.500000e+01\n",
       "mean    0.345882   0.148049     0.089377   0.093803  4.693753e+09\n",
       "std     0.275401   0.347485     0.068611   0.293993  1.107719e+09\n",
       "min     0.000000   0.000100     0.015301   0.003676  4.295869e+09\n",
       "25%     0.200000   0.010000     0.041463   0.016492  4.295895e+09\n",
       "50%     0.300000   0.010000     0.062155   0.028661  4.295895e+09\n",
       "75%     0.500000   0.010000     0.114836   0.047029  4.295899e+09\n",
       "max     1.000000   1.000000     0.312227   2.334567  8.589934e+09"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m3.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa701328",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T18:20:08.407575Z",
     "start_time": "2023-08-09T18:20:08.393026Z"
    }
   },
   "outputs": [],
   "source": [
    "combine_df = pd.concat([df_m1, df_m2, df_m2 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "64d357df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T18:20:14.880347Z",
     "start_time": "2023-08-09T18:20:14.852876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1 Ratio</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Best Scores</th>\n",
       "      <th>MSE</th>\n",
       "      <th>Asset IDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>2.550000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.252941</td>\n",
       "      <td>0.236631</td>\n",
       "      <td>0.086584</td>\n",
       "      <td>0.087574</td>\n",
       "      <td>4.693753e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.279026</td>\n",
       "      <td>0.415466</td>\n",
       "      <td>0.066659</td>\n",
       "      <td>0.281493</td>\n",
       "      <td>1.103349e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.015274</td>\n",
       "      <td>0.003928</td>\n",
       "      <td>4.295869e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.040861</td>\n",
       "      <td>0.016215</td>\n",
       "      <td>4.295895e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.059346</td>\n",
       "      <td>0.029177</td>\n",
       "      <td>4.295895e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.111810</td>\n",
       "      <td>0.044632</td>\n",
       "      <td>4.295899e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.318984</td>\n",
       "      <td>2.334567</td>\n",
       "      <td>8.589934e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         L1 Ratio       Alpha  Best Scores         MSE     Asset IDs\n",
       "count  255.000000  255.000000   255.000000  255.000000  2.550000e+02\n",
       "mean     0.252941    0.236631     0.086584    0.087574  4.693753e+09\n",
       "std      0.279026    0.415466     0.066659    0.281493  1.103349e+09\n",
       "min      0.000000    0.000100     0.015274    0.003928  4.295869e+09\n",
       "25%      0.000000    0.001000     0.040861    0.016215  4.295895e+09\n",
       "50%      0.200000    0.010000     0.059346    0.029177  4.295895e+09\n",
       "75%      0.400000    0.100000     0.111810    0.044632  4.295899e+09\n",
       "max      1.000000    1.000000     0.318984    2.334567  8.589934e+09"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afbdd1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cf63949",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T21:44:04.975506Z",
     "start_time": "2023-08-07T21:44:04.914229Z"
    }
   },
   "outputs": [],
   "source": [
    "df_m1 = pd.read_csv('../results/EN-M1-GRIDSEARCH.csv')\n",
    "df_m2 = pd.read_csv('../results/EN-M2-GRIDSEARCH.csv')\n",
    "df_m3 = pd.read_csv('../results/EN-M3-GRIDSEARCH.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "984895f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-07T21:44:36.229138Z",
     "start_time": "2023-08-07T21:44:36.223201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the result of m1 test data: 0.0846339894766677\n",
      "the result of m2 test data: 0.08904331794611786\n",
      "the result of m3 test data: 0.09380348811801345\n"
     ]
    }
   ],
   "source": [
    "print('the result of m1 test data:', np.mean(df_m1['MSE']))\n",
    "print('the result of m2 test data:', np.mean(df_m2['MSE']))\n",
    "print('the result of m3 test data:', np.mean(df_m3['MSE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc1b872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03656b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2055857b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bccefd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
